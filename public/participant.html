<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>LiveKit Participant</title>
  <style>
    body { background: #111; color: #fff; font-family: Arial; padding: 20px; }
    h2 { color: #0af; margin-bottom: 15px; }
    .video-grid {
      display: flex;
      gap: 20px;
      padding: 20px;
      background: #222;
      border-radius: 8px;
      flex-wrap: wrap;
      justify-content: center;
    }
    .video-container {
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    .tile {
      width: 400px;
      height: 300px;
      background: black;
      border: 2px solid #444;
      border-radius: 4px;
      object-fit: cover;
    }
    .meter-label {
      margin-top: 5px;
      width: 80%;
      text-align: center;
      font-size: 12px;
      color: #ccc;
    }
    progress {
      width: 100%;
      height: 10px;
    }
  </style>
</head>
<body>

<h2>Participant</h2>

<div class="video-grid">
  <div class="video-container">
    <video id="local-video" class="tile" autoplay muted playsinline></video>
    <div class="meter-label">My Mic: <progress id="local-meter" value="0" max="100"></progress></div>
  </div>
  <div class="video-container">
    <video id="remote-video" class="tile" autoplay playsinline></video>
    <div class="meter-label">Remote Mic: <progress id="remote-meter" value="0" max="100"></progress></div>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/livekit-client/dist/livekit-client.umd.min.js"></script>
<script>
  const { Room, RoomEvent, Track } = LivekitClient;
  let room;
  let audioCtx;

  /* ================= AUDIO CONTEXT ================= */
  function ensureAudioContext() {
    if (!audioCtx) {
      audioCtx = new (window.AudioContext || window.webkitAudioContext)();
    }
  }

  /* ================= AUDIO METER ================= */
  function createMeter(stream, meterId) {
    ensureAudioContext();
    const source = audioCtx.createMediaStreamSource(stream);
    const analyser = audioCtx.createAnalyser();
    analyser.fftSize = 256;
    source.connect(analyser);

    const dataArray = new Uint8Array(analyser.frequencyBinCount);
    const meter = document.getElementById(meterId);

    function update() {
      analyser.getByteFrequencyData(dataArray);
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) sum += dataArray[i];
      if (meter) meter.value = (sum / dataArray.length) * 1.5;
      requestAnimationFrame(update);
    }
    update();
  }

  /* ================= ROOM SETUP ================= */
  async function start() {
    const identity = "participant-" + Math.floor(Math.random() * 1000);
    const res = await fetch(`/api/get-token?room=my-room&identity=${identity}`);
    const { token } = await res.json();

    room = new Room({ adaptiveStream: true, dynacast: true });

    room.on(RoomEvent.TrackSubscribed, track => {
      if (track.kind === Track.Kind.Video) {
        track.attach(document.getElementById("remote-video"));
      }
      if (track.kind === Track.Kind.Audio) {
        createMeter(new MediaStream([track.mediaStreamTrack]), "remote-meter");
      }
    });

    await room.connect("wss://my-first-app-mwgdyws7.livekit.cloud", token);

    // Local camera
    await room.localParticipant.setCameraEnabled(true);
    const camPub = room.localParticipant.getTrackPublication(Track.Source.Camera);
    camPub?.videoTrack?.attach(document.getElementById("local-video"));

    // Local microphone
    await room.localParticipant.setMicrophoneEnabled(true);
    const micPub = room.localParticipant.getTrackPublication(Track.Source.Microphone);
    if (micPub?.audioTrack) {
      createMeter(new MediaStream([micPub.audioTrack.mediaStreamTrack]), "local-meter");
    }
  }

  /* ================= BOOT ================= */
  start();
</script>
</body>
</html>